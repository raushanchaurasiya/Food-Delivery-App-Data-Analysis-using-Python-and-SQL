{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd7ff497",
   "metadata": {},
   "source": [
    "## Module-1 Data PreProcessing (Week-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f10ead1",
   "metadata": {},
   "source": [
    "In this module, you will query the dataset using structured query language to gain insights from the database. The problem statements to be solved will be provided to you, and you will need to provide the solution for the same using your logic. Different concepts of SQL will be used in this process, such as aggregating the data, grouping the data, ordering the data, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aabe47b",
   "metadata": {},
   "source": [
    "**Task: 1 Pre-Processing the data and Removing Unwanted Columns**\n",
    "\n",
    "In this module, you will query the dataset using structured query language to gain insights from the database. The problem statements to be solved will be provided to you and you need to provide the solution for the same using your logic. Different concepts of SQL will be used in this process such as aggregating the data, grouping the data, ordering the data, etc. Module 1 consists of subtasks which are as follows\n",
    "\n",
    "**Pre-processing the data:**\n",
    "\n",
    "Data Pre-processing is one of the important steps in data analytics because data that is not processed can lead to different unwanted results when the data will be used for further applications. This task includes sub-tasks such as handling null values, deletion or transformation of irrelevant values, datatype transformation, removing duplicates, etc. The tasks to be performed for cleaning the data set are given below:\n",
    "\n",
    "**Removing Unwanted Columns:**\n",
    "\n",
    "Removing unwanted columns refers to the process of eliminating irrelevant or unnecessary columns from a dataset. This can improve data analysis and visualization by reducing clutter and focusing on the most important information. It involves identifying and selecting the columns to be removed and executing the removal process using tools like programming languages, database management systems, or spreadsheet software.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b37f1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22120726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_from_csv():\n",
    "    hotels=pd.read_csv('zomato.csv')\n",
    "    return hotels\n",
    "\n",
    "def remove_unwanted_columns():\n",
    "    #DO NOT REMOVE FOLLOWING LINE\n",
    "    #call read_data_from_csv() function to get dataframe\n",
    "    hotels=read_data_from_csv()\n",
    "    hotels = hotels.drop(['address','phone'], axis =1)\n",
    "    return hotels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467fefe8",
   "metadata": {},
   "source": [
    "**Task: 2 Renaming and selecting Columns in a dataset**\n",
    "\n",
    "\n",
    "Renaming columns involves changing the names of one or more columns in a dataset to make them more meaningful or consistent. Selecting columns refers to the process of choosing only specific columns to be included in a dataset while excluding all others. These techniques are useful for improving the organization and readability of data and can help streamline data analysis. By renaming and selecting only the relevant columns, data scientists can create a more focused and manageable dataset that is better suited for their specific analysis needs.\n",
    "Only these columns are allowed in the dataset:\n",
    "1.    Id 2.    Name 3.    online_order 4.    book_table 5.    rating 6.    votes 7.    location 8.    rest_type \n",
    "       9.    dish_liked 10.    cuisines 11.    approx_cost 12.    type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976ea34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns():\n",
    "    #DO NOT REMOVE FOLLOWING LINE\n",
    "    #call remove_unwanted_columns() function to get dataframe\n",
    "    hotels = remove_unwanted_columns()\n",
    "    hotels.rename(columns ={'rate':'rating','approx_cost(for two people)':'approx_cost','listed_in(type)':'type'},inplace = True)\n",
    "    #task2: rename columns,  only these columns are allowed in the dataset\n",
    "    return hotels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd604778",
   "metadata": {},
   "source": [
    "**Task: 3 Dealing with Null values in a dataset**\n",
    "\n",
    "Handling null values refers to the process of identifying and addressing missing or incomplete data in each column of a dataset. This involves using techniques like imputation, where missing values are replaced with estimated values based on other data, or deletion, where incomplete records are removed entirely. Proper handling of null values is critical for accurate data analysis and can help prevent bias and errors in results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d70f824",
   "metadata": {},
   "outputs": [],
   "source": [
    "#task3: handle  null values of each column\n",
    "def null_value_check():\n",
    "    #DO NOT REMOVE FOLLOWING LINE\n",
    "    #call rename_columns() function to get dataframe\n",
    "    hotels=rename_columns()\n",
    "    \n",
    "    #deleting null values of name column\n",
    "    hotels = hotels.dropna(subset = ['name'])\n",
    "    #handling null values of online_order\n",
    "    hotels['online_order'].fillna(\"NA\",inplace = True)\n",
    "    #handling null values of book_table\n",
    "    hotels['book_table'].fillna(\"NA\",inplace = True)\n",
    "    #handling null values of rating\n",
    "    hotels['rating'].fillna(0,inplace = True)\n",
    "    #handling null values of votes\n",
    "    hotels['votes'].fillna(0,inplace = True)\n",
    "    #handling null values of location\n",
    "    hotels['location'].fillna(\"NA\",inplace = True)\n",
    "    #handling null values of rest_type\n",
    "    hotels['rest_type'].fillna(\"NA\",inplace = True)\n",
    "    #handling null values of dishliked\n",
    "    hotels['dish_liked'].fillna(\"NA\",inplace = True)\n",
    "    #handling null values of cuisines\n",
    "    hotels['cuisines'].fillna(\"NA\",inplace = True)\n",
    "    #handling null values of approxcost\n",
    "    hotels['approx_cost'].fillna(0,inplace = True)\n",
    "    #handling null values of type\n",
    "    hotels['type'].fillna(\"NA\",inplace = True)\n",
    "    return hotels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c7dee8",
   "metadata": {},
   "source": [
    "**Task: 4 Identifying Duplicate data in a dataset.**\n",
    "\n",
    "\n",
    "Finding duplicates in a dataset refers to the process of identifying records that are identical or nearly identical to one another. Duplicate data can skew analysis results and waste computational resources, so it is important to identify and remove duplicates before analyzing data. This can be achieved using algorithms that compare records and identify common attributes, or through manual inspection of the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36636a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#task4 #find duplicates in the dataset\n",
    "def find_duplicates():\n",
    "    #DO NOT REMOVE FOLLOWING LINE\n",
    "    #call null_value_check() function to get dataframe\n",
    "    hotels=null_value_check()\n",
    "    hotels = hotels.drop_duplicates(keep = \"first\")\n",
    "    #droping the duplicates value keeping the first\n",
    "    return hotels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eec318d",
   "metadata": {},
   "source": [
    "**Task: 5 Text Cleaning**\n",
    "\n",
    "\n",
    "Text cleaning refers to the process of removing irrelevant or unnecessary text from all the columns in a dataset. This is an essential step in data preprocessing and analysis, as it ensures that the data is accurate and reliable. Text cleaning can involve tasks such as removing stopwords, punctuation, and special characters, as well as correcting spelling and grammar errors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4c3757",
   "metadata": {},
   "outputs": [],
   "source": [
    "#task5 removing irrelevant text from all the columns\n",
    "def removing_irrelevant_text():\n",
    "    #DO NOT REMOVE FOLLOWING LINE\n",
    "    #call find_duplicates() function to get dataframe\n",
    "    hotels= find_duplicates()\n",
    "    \n",
    "    hotels=hotels[hotels['online_order'].str.contains('RATED|Rated')==False]\n",
    "    hotels=hotels[hotels['book_table'].str.contains('RATED|Rated')==False]\n",
    "    hotels=hotels[hotels['rest_type'].str.contains('RATED|Rated')==False]\n",
    "    hotels=hotels[hotels['online_order'].str.contains('RATED|Rated')==False]\n",
    "    hotels=hotels[hotels['rating'].str.contains('RATED|Rated')==False]\n",
    "    hotels=hotels[hotels['name'].str.contains('RATED|Rated')==False]\n",
    "    hotels=hotels[hotels['location'].str.contains('RATED|Rated')==False]\n",
    "    hotels=hotels[hotels['approx_cost'].str.contains('RATED|Rated')==False]\n",
    "    hotels=hotels[hotels['type'].str.contains('RATED|Rated')==False]\n",
    "    hotels=hotels[hotels['votes'].str.contains('RATED|Rated')==False]\n",
    "    hotels=hotels[hotels['dish_liked'].str.contains('RATED|Rated')==False]\n",
    "\n",
    "    return hotels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9404021c",
   "metadata": {},
   "source": [
    "**Task: 6 Unique Value check and Irrelevant value handling**\n",
    "\n",
    "\n",
    "The process of examining each column in a dataset to identify and handle any irrelevant data, while also verifying the uniqueness of values within each column. This helps ensure data accuracy and integrity in analysis and decision-making.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ff22cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#task6: check for unique values in each column and handle the irrelevant values\n",
    "def check_for_unique_values():\n",
    "    #DO NOT REMOVE FOLLOWING LINE\n",
    "    #call removing_irrelevant_text() function to get dataframe\n",
    "    hotels=removing_irrelevant_text()\n",
    "    hotels=hotels[hotels['online_order'].str.contains('Yes|No')==True]\n",
    "    # for i in range(0,len(hotels)):\n",
    "    #     hotels.iloc[i].rating = hotels.iloc[i].rating[:3]\n",
    "    hotels['rating'] = hotels['rating'].apply(lambda x : 0 if x == 'NEW' else x)\n",
    "    hotels['rating'] = hotels['rating'].apply(lambda x : 0 if x == '-' else x)\n",
    "    #hotels['rating'] = hotels['rating'].str.slice(0, 3)\n",
    "    # hotels['rating'] = hotels['rating'].apply(lambda str(x): x[:3])\n",
    "    hotels['rating'] = hotels.rating.str.split('/').str[0]\n",
    "    hotels['rating'].fillna(0,inplace = True)\n",
    "    return hotels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933b6589",
   "metadata": {},
   "source": [
    "**Task: 7 Cleaning and exporting Zomato Dataset**\n",
    "\n",
    "\n",
    "The process of cleaning the Zomato dataset by removing any unknown or unidentifiable characters and exporting the cleaned dataset to a new file named \"zomatocleaned.csv\". This involves identifying and removing any symbols, special characters, or non-standard characters that may interfere with proper data analysis. By exporting the cleaned dataset to a new file, the original dataset can be preserved and the cleaned data can be easily accessed for further analysis and decision-making.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba57d930",
   "metadata": {},
   "outputs": [],
   "source": [
    "#task7: remove the unknown character from the dataset and export it to \"zomatocleaned.csv\"\n",
    "def remove_the_unknown_character():\n",
    "    #DO NOT REMOVE FOLLOWING LINE\n",
    "    #call check_for_unique_values() function to get dataframe\n",
    "    dataframe=check_for_unique_values()\n",
    "    # task7:to remove the unknown charachter from name column:\n",
    "    # replace the string having regex [Ãx][^A-Za-z]+ with ''\n",
    "    dataframe['name'] = dataframe['name'].replace(to_replace = \"[Ãx][^A-Za-z]+\" ,value=\"\",regex=True)\n",
    "\n",
    "    #remove unknown character from dataset    \n",
    "    #export cleaned Dataset to newcsv file named \"zomatocleaned.csv\"\n",
    "    dataframe.to_csv('zomatocleaned_v1.csv')\n",
    "    return dataframe\n",
    "\n",
    "#check if mysql table is created using \"zomatocleaned.csv\"\n",
    "#Use this final dataset and upload it on the provided database for performing analysis in  MySQL\n",
    "#To Run this task first Run the appliation for Terminal to create table named 'Zomato' and then run test.\n",
    "def start():\n",
    "    remove_the_unknown_character()\n",
    "\n",
    "def task_runner():\n",
    "    start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cee1843",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
